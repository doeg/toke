{"version":3,"sources":["../../src/toke.js"],"names":[],"mappings":";;;;;;;;;;;;0BAAoB,gBAAgB;;;;0BACpB,gBAAgB;;;;wBACX,YAAY;;;;AAEjC,IAAM,KAAK,GAAG,CAAC,CAAC;;;;;;AAKT,SAAS,OAAO,CAAC,MAAM,EAAE,GAAG,EAAE,CAAC,EAAE;;;AACtC,MAAI,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;AACf,MAAI,QAAQ,GAAG,EAAE,CAAC;AAClB,MAAI,MAAM,GAAG,IAAI,CAAC;;AAElB,QAAM,CAAC,OAAO,CAAC,UAAA,KAAK,EAAI;;AAEtB,QAAI,WAAW,GAAG,MAAK,YAAY,CAAC,KAAK,EAAE,GAAG,CAAC,CAAC;;;;AAIhD,QAAI,WAAW,KAAK,IAAI,EAAE;AACxB,YAAM,GAAG,MAAM,IAAI,IAAI,CAAC;AACxB,cAAQ,CAAC,IAAI,CAAC,KAAK,CAAC,CAAA;KACrB;;;;;SAKI;AACH,cAAM,GAAG,MAAM,IAAI,KAAK,CAAC;AACzB,gBAAQ,GAAG,QAAQ,CAAC,MAAM,CAAC,WAAW,CAAC,CAAC;OACzC;GACF,CAAC,CAAC;;AAEH,SAAO,MAAM,GAAG,QAAQ,GAAG,IAAI,CAAC,OAAO,CAAC,QAAQ,EAAE,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC;CAC7D;;AAAA,CAAC;;;;;;;;AAOK,SAAS,YAAY,CAAC,KAAK,EAAE,GAAG,EAAE;;AAEvC,MAAI,EAAE,KAAK,IAAI,GAAG,CAAA,AAAC,EAAE;AACnB,UAAM,IAAI,KAAK,CAAC,iBAAiB,GAAG,KAAK,CAAC,CAAC;GAC5C;;AAED,MAAI,YAAY,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC;;AAE9B,MAAI,YAAY,KAAK,IAAI,EAAE;AACzB,WAAO,IAAI,CAAC;GACb,MAAM;AACL,QAAI,GAAG,GAAG,YAAY,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,GAAC,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC;AACtE,QAAI,CAAC,KAAK,CAAC,OAAO,CAAC,GAAG,CAAC,EAAE,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC;AACrC,WAAO,GAAG,CAAC;GACZ;CACF;;AAAA,CAAC;;;;;;;AAMK,SAAS,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE;AACxC,MAAI,GAAG,GAAG,EAAE,CAAC;AACb,OAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;;AAEtC,QAAI,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;AACtB,QAAI,EAAE,KAAK,IAAI,OAAO,CAAA,AAAC,EAAE;AACvB,YAAM,IAAI,KAAK,CAAC,SAAS,GAAG,KAAK,GAAG,wBAAwB,CAAC,CAAC;KAC/D;;AAED,QAAI,KAAK,GAAG,OAAO,CAAC,KAAK,CAAC,CAAC;AAC3B,QAAI,IAAI,GAAG,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,GAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC;AACzD,OAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;GAChB;AACD,SAAO,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;CACtB;;AAAA,CAAC;;AAEK,SAAS,EAAE,CAAC,GAAG,EAAE,IAAI,EAAE;AAC5B,MAAI,MAAM,GAAG,2BAAS,GAAG,CAAC,CAAC,GAAG,CAAC,UAAA,CAAC;WAAI,CAAC,CAAC,KAAK;GAAA,CAAC,CAAC;AAC7C,MAAI,QAAQ,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,0BAAU,CAAC;AAC7C,SAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,0BAAM,CAAC;CACrC;;AAAA,CAAC","file":"toke.js","sourcesContent":["import grammar from \"../lib/grammar\";\nimport LEX from \"../lib/lexicon\";\nimport tokenize from \"./tokenize\";\n\nconst LIMIT = 3;\n\n/**\n * Compiles the string down to its base tokens.\n */\nexport function compile(tokens, pos, i) {\n  var i = i || 0;\n  var compiled = [];\n  var isDone = true;\n\n  tokens.forEach(token => {\n\n    var constituent = this.compileToken(token, pos);\n\n    // Terminal tokens get compiled to null, meaning that the token is\n    // its own constituent and needs no further recursion.\n    if (constituent === null) {\n      isDone = isDone && true;\n      compiled.push(token)\n    }\n\n    // Otherwise, if the token is not terminal, push its compiled constituents\n    // onto the final phrase grammar and indicate that at least one more\n    // recursive step is needed\n    else {\n      isDone = isDone && false;\n      compiled = compiled.concat(constituent);\n    }\n  });\n\n  return isDone ? compiled : this.compile(compiled, pos, i++);\n};\n\n/**\n * For a single token (\"NP\"), returns a randomly-chosen constituent phrase\n * ([\"Det\", \"N\"]), as given by the rules in pos. If the token is already\n * terminal, null is returned.\n */\nexport function compileToken(token, pos) {\n\n  if (!(token in pos)) {\n    throw new Error(\"invalid token: \" + token);\n  }\n\n  var constituents = pos[token];\n\n  if (constituents === null) {\n    return null;\n  } else {\n    var sub = constituents[Math.floor(Math.random()*constituents.length)];\n    if (!Array.isArray(sub)) sub = [sub];\n    return sub;\n  }\n};\n\n/**\n * Populates an array of base tokens with actual words.\n * TODO: this can probably be combined with compile() for simplicity.\n */\nexport function populate(tokens, lexicon) {\n  var str = [];\n  for (var i = 0; i < tokens.length; i++) {\n\n    var token = tokens[i];\n    if (!(token in lexicon)) {\n      throw new Error(\"token '\" + token + \"' not known in lexicon\");\n    }\n\n    var words = lexicon[token];\n    var word = words[Math.floor(Math.random()*words.length)];\n    str.push(word);\n  }\n  return str.join(\" \");\n};\n\nexport function mk(str, opts) {\n  var tokens = tokenize(str).map(t => t.token);\n  var compiled = this.compile(tokens, grammar);\n  return this.populate(compiled, LEX);\n};\n\n"]}